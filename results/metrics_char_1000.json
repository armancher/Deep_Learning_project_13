{
  "checkpoint": "checkpoints/WikiText/nanogpt_char_step1000.pt",
  "dataset_eval": "data/WikiText.txt",
  "dataset_train": "data/Wikitext.txt",
  "tokenizer": "char",
  "vocab_size": 283,
  "loss": 1.6098857761057146,
  "perplexity": 5.002240180969238,
  "bits_per_token": 2.3225742255853947,
  "bits_per_char": 2.3225742255853947,
  "eval_tokens": 10810591,
  "eval_chars": 10810591,
  "num_params": 10854528,
  "train_steps": 1000,
  "train_time_sec": 2495.3820202350616,
  "train_steps_per_sec": 0.4007402441353654
}
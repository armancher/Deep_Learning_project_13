{
  "loss": 3.152447461380678,
  "perplexity": 23.39324951171875,
  "bits_per_token": 4.548020319196906,
  "bits_per_character": 2.8352032624434136,
  "bits_per_byte": 2.8352032624434136,
  "compression_ratio_chars": 1.6041249597312348,
  "compression_ratio_bytes": 1.6041249597312348,
  "tokens_per_parameter": 0.06357077657632355,
  "total_bytes_processed": 1115393,
  "total_tokens_processed": 695328,
  "total_chars_processed": 1115393,
  "tokenization_efficiency": {
    "tokens_per_char": 0.6233928310469942,
    "chars_per_token": 1.6041249597312348,
    "bytes_per_token": 1.6041249597312348,
    "sample_tokens_per_char": 0.75,
    "sample_compression_ratio": 1.3333333333333333,
    "sample_bits_per_byte": 3.4110152393976794
  },
  "training_efficiency": {
    "train_steps_per_sec": 5.314718619762441,
    "estimated_tokens_per_second": 43538.17493309392
  },
  "timestamp": "2025-11-30T19:51:20.272238",
  "checkpoint": "checkpoints/nanogpt_bpe_step200.pt",
  "dataset_eval": "data/tiny_shakespeare.txt",
  "dataset_train": "data/tiny_shakespeare.txt",
  "tokenizer": "bpe",
  "vocab_size": 500,
  "num_params": 10937856,
  "train_steps": 200,
  "train_time_sec": 37.631343126297,
  "train_steps_per_sec": 5.314718619762441
}
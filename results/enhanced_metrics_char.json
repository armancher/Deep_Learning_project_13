{
  "loss": 2.4591580429216373,
  "perplexity": 11.69495964050293,
  "bits_per_token": 3.547815113285255,
  "bits_per_character": 3.547815113285255,
  "bits_per_byte": 3.547815113285255,
  "compression_ratio_chars": 1.0,
  "compression_ratio_bytes": 1.0,
  "tokens_per_parameter": 0.10355696355782143,
  "total_bytes_processed": 1115393,
  "total_tokens_processed": 1115393,
  "total_chars_processed": 1115393,
  "tokenization_efficiency": {
    "tokens_per_char": 1.0,
    "chars_per_token": 1.0,
    "bytes_per_token": 1.0,
    "sample_tokens_per_char": 1.0,
    "sample_compression_ratio": 1.0,
    "sample_bits_per_byte": 3.547815113285255
  },
  "training_efficiency": {
    "train_steps_per_sec": 3.7961371058644136,
    "estimated_tokens_per_second": 31097.955171241276
  },
  "timestamp": "2025-11-30T19:01:56.496188",
  "checkpoint": "checkpoints/Shakespeare/nanogpt_char_step200.pt",
  "dataset_eval": "data/tiny_shakespeare.txt",
  "dataset_train": "data/tiny_shakespeare.txt",
  "tokenizer": "char",
  "vocab_size": 65,
  "num_params": 10770816,
  "train_steps": 200,
  "train_time_sec": 52.68513607978821,
  "train_steps_per_sec": 3.7961371058644136
}